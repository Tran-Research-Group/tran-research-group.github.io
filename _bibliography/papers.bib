@inproceedings{antul2018,
  title = {Toward {{Scaling Model-Based Engineering}} for {{Systems}} of {{Systems}}},
  booktitle = {2018 {{IEEE Aerospace Conference Proceedings}}},
  author = {Antul, Laura and Ricks, Sean and Cho, Lance and Cotter, Matt and Jacobs, Ryan B and {Markina-Khusid}, Aleksandra and Kamenetsky, Janna and Dahmann, Judith and Tran, Huy T},
  year = {2018},
  pages = {1--9},
  address = {Big Sky, MT},
  doi = {10.1109/AERO.2018.8396427},
  isbn = {978-1-5386-2014-4},
  file = {/Users/httran/Zotero/storage/HBPTRXZJ/Antul et al. - 2018 - Toward Scaling Model-Based Engineering for Systems of Systems.pdf}
}

@inproceedings{balchanos2014,
  title = {Metrics-Based {{Analysis}} and {{Evaluation Framework}} for {{Engineering Resilient Systems}}},
  booktitle = {2014 7th {{International Symposium}} on {{Resilient Control Systems}}},
  author = {Balchanos, Michael G and Domercant, Jean Charles and Tran, Huy T and Mavris, Dimitri N},
  year = {2014},
  publisher = {IEEE},
  address = {Denver, CO},
  doi = {10.1109/ISRCS.2014.6900107},
  file = {/Users/httran/Zotero/storage/5X332CLI/2014-Metrics-based_Analysis_and_Evaluation_Framework_for_Engineering_Resilient_Systems.pdf}
}

@inproceedings{chandramouleeswaran2018,
  title = {Machine {{Learning Prediction}} of {{Airport Delays}} in the {{US Air Transportation Network}}},
  booktitle = {18th {{AIAA Aviation Technology}}, {{Integration}}, and {{Operations Conference}}},
  author = {Chandramouleeswaran, Keshav Ram and Tran, Huy T},
  year = {2018},
  doi = {10.2514/6.2018-3672},
  file = {/Users/httran/Zotero/storage/Y4TUK948/Chandramouleeswaran, Tran - 2018 - Machine Learning Prediction of Airport Delays in the US Air Transportation Network.pdf}
}

@inproceedings{chandramouleeswaran2018a,
  title = {Data-Driven {{Resilience Quantification}} of the {{US Airline Network}}},
  booktitle = {2018 {{Annual IEEE International Systems Conference}} ({{SysCon}})},
  author = {Chandramouleeswaran, Keshav Ram and Tran, Huy T},
  year = {2018},
  pages = {1--6},
  address = {Vancouver, CA},
  doi = {10.1109/SYSCON.2018.8369602},
  file = {/Users/httran/Zotero/storage/AICI6H8L/Chandramouleeswaran, Tran - 2018 - Data-driven Resilience Quantification of the US Airline Network (submitted).pdf}
}

@inproceedings{dimon2022,
  title = {D-{{AnoGAN}}: {{Anomaly Detection}} in {{Disconnected Data Manifolds}} with {{Generative Adversarial Networks}}},
  booktitle = {2022 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Dimon, Walker L and Chase, Nicholas B and Stralen, Neale Van and Nigam, Rupal and Lembeck, Michael F and Tran, Huy T},
  year = {2022},
  address = {Padua, Italy},
  doi = {10.1109/IJCNN55064.2022.9892270},
  file = {/Users/httran/Zotero/storage/AHWKUM57/Dimon et al. - 2022 - D-AnoGAN Anomaly Detection in Disconnected Data M.pdf}
}

@article{gasparino2022,
  title = {{{WayFAST}}: {{Traversability Predictive Navigation}} for {{Field Robots}}},
  author = {Gasparino, Mateus V and Sivakumar, Arun N and Liu, Yixiao and Velasquez, Andres E B and Higuti, Vitor A H and Rogers, John and Tran, Huy and Chowdhary, Girish},
  year = {2022},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {Early Access},
  doi = {10.1109/LRA.2022.3193464},
  url = {https://arxiv.org/pdf/2203.12071.pdf},
  abstract = {We present a self-supervised approach for learning to predict traversable paths for wheeled mobile robots that require good traction to navigate. Our algorithm, termed WayFAST (Waypoint Free Autonomous Systems for Traversability), uses RGB and depth data, along with navigation experience, to autonomously generate traversable paths in outdoor unstructured environments. Our key inspiration is that traction can be estimated for rolling robots using kinodynamic models. Using traction estimates provided by an online receding horizon estimator, we are able to train a traversability prediction neural network in a self-supervised manner, without requiring heuristics utilized by previous methods. We demonstrate the effectiveness of WayFAST through extensive field testing in varying environments, ranging from sandy dry beaches to forest canopies and snow covered grass fields. Our results clearly demonstrate that WayFAST can learn to avoid geometric obstacles as well as untraversable terrain, such as snow, which would be difficult to avoid with sensors that provide only geometric data, such as LiDAR. Furthermore, we show that our training pipeline based on online traction estimates is more data-efficient than other heuristic-based methods.},
  langid = {english},
  file = {/Users/httran/Zotero/storage/Z5URQHQM/Gasparino et al. - WayFAST Traversability Predictive Navigation for .pdf}
}

@inproceedings{heglund2020,
  title = {Railway {{Delay Prediction}} with {{Spatial-Temporal Graph Convolutional Networks}}},
  booktitle = {2020 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  author = {Heglund, Jacob S W and Taleongpong, Panukorn and Hu, Simon and Tran, Huy T},
  year = {2020},
  pages = {1--6},
  doi = {10.1109/ITSC45102.2020.9294742},
  file = {/Users/httran/Zotero/storage/8N9HQ385/Heglund et al. - 2020 - Railway Delay Prediction with Spatial-Temporal Graph Convolutional Networks(2).pdf}
}

@article{heglund2021,
  title = {Social Sensing: Towards Social Media as a Sensor for Resilience in Power Systems and Other Critical Infrastructures},
  author = {Heglund, Jacob and Hopkinson, Kenneth M. and Tran, Huy T.},
  year = {2021},
  journal = {Sustainable and Resilient Infrastructure},
  volume = {6},
  number = {1-2},
  pages = {94--106},
  publisher = {Taylor \& Francis},
  issn = {2378-9689},
  doi = {10.1080/23789689.2020.1719728},
  keywords = {critical infrastructures,Critical infrastructures,hurricane,Hurricane Sandy,power systems,resilience,social media},
  file = {/Users/httran/Zotero/storage/ZJAIG4WA/Heglund, Hopkinson, Tran - 2021 - Social sensing towards social media as a sensor for resilience in power systems and other critical (2).pdf}
}

@inproceedings{heglund2024,
  title = {Coordination {{Machines}} for {{Minimizing Communication}} in {{Multi-Agent Reinforcement Learning}}},
  booktitle = {{{RLC}} 2024 {{Workshop CoCoMARL}}},
  author = {Heglund, Jacob and Tran, Huy},
  year = {2024},
  url = {https://openreview.net/pdf?id=SnTvlVU7xr},
  abstract = {Multi-agent systems (MAS) are a promising solution for many real-world problems. However, complete and perfect communications are not guaranteed in the real-world. A key problem in MAS is thus ensuring that agents can meet global specifications while minimizing communication cost. We approach this problem by proposing a hierarchical model that decomposes a global, multi-agent task given by a linear temporal logic (LTL) formula into an equivalent automaton defined over subtasks given as LTL formulae. Our key idea is that each subtask may require different levels of inter-agent communication, and that modeling a global task as the composition of subtasks enables context-aware communication. To solve this problem, we formulate a hierarchical agent which solves an optimization problem to ensure an MAS satisfies a probabilistic task-completion specification while minimizing inter-agent communication. We then develop an algorithm to optimize the hierarchical agent based on the performance of a low-level team of agents that are trained to solve subtasks using multi-agent reinforcement learning (MARL). We then compare our approach to a baseline monolithic task model that approximates a common formulation used in MARL, and show our method provides a significant reduction in communication cost compared to the baseline.},
  langid = {english},
  file = {/Users/httran/Zotero/storage/ZUETCKC5/Heglund and Tran - 2024 - Coordination Machines for Minimizing Communi- cation in Multi-Agent Reinforcement Learning.pdf}
}

@inproceedings{kim2022,
  title = {Disentangling {{Successor Features}} for {{Coordination}} in {{Multi-agent Reinforcement Learning}}},
  booktitle = {Proc. of the 21st {{International Conference}} on {{Autonomous Agents}} and {{Multiagent Systems}} ({{AAMAS}} 2022)},
  author = {Kim, Seung Hyun and Stralen, Neale Van and Chowdhary, Girish and Tran, Huy T},
  year = {2022},
  address = {London, UK},
  doi = {10.48550/arXiv.2202.07741},
  url = {https://www.ifaamas.org/Proceedings/aamas2022/pdfs/p751.pdf},
  file = {/Users/httran/Zotero/storage/XTXFSPCF/Kim et al. - 2022 - Coordination in Multi-agent Reinforcement Learning.pdf}
}

@article{markina-khusid2022,
  title = {A {{Complex Network Framework}} for {{Validated Assessments}} of {{Systems}} of {{Systems Robustness}}},
  author = {{Markina-khusid}, Aleksandra and Jacobs, Ryan B and Antul, Laura and Cho, Lance and Tran, Huy T},
  year = {2022},
  journal = {IEEE Systems Journal},
  volume = {16},
  number = {1},
  pages = {1092--1102},
  doi = {10.1109/JSYST.2021.3064817},
  file = {/Users/httran/Zotero/storage/AFEX8N88/Markina-khusid et al. - 2021 - A Complex Network Framework for Validated Assessments of Systems of Systems Robustness.pdf}
}

@article{napier2020,
  title = {An {{Artificial Neural Network Approach}} to {{Generating High-Resolution Designs}} from {{Low-Resolution Input}} in {{Topology Optimization}}},
  author = {Napier, Nicholas A. and Sriraman, Sai-Aksharah and Tran, Huy T. and James, Kai A.},
  year = {2020},
  journal = {Journal of Mechanical Design},
  volume = {142},
  number = {1},
  issn = {1050-0472},
  doi = {10.1115/1.4044332},
  url = {https://mechanicaldesign.asmedigitalcollection.asme.org/article.aspx?articleid=2740327},
  file = {/Users/httran/Zotero/storage/4SXTJXKC/Napier et al. - 2019 - An Artificial Neural Network Approach to Generating High-Resolution Designs from Low-Resolution Input in Topol(2).pdf}
}

@inproceedings{nigam2023,
  title = {Coordination in {{Ad Hoc Teams}} with {{Generalized Policy Improvement}}},
  booktitle = {{{IROS}} 2023 {{Workshop}} on {{Advances}} in {{Multi- Agent Learning}} - {{Coordination}}, {{Perception}}, and {{Control}}},
  author = {Nigam, Rupal and Parikh, Niket and Heglund, Jacob and Yuasa, Mikihisa and Tran, Huy T},
  year = {2023},
  address = {Detroit, MI},
  url = {https://djhanove.github.io/IROS23\_MRS/assets/papers/IROS\_MRS\_2023\_AdhocTeams.pdf},
  abstract = {Multi-agent reinforcement learning (MARL) is a recently popular approach for solving complex tasks with multiple agents present. Ad hoc teaming (AHT) is a more specific problem formulation in which an agent must successfully coordinate with other previously unseen teammates. We model our problem within the framework of a multi-agent Markov decision process (MMDP) and use successor features and generalized policy improvement for efficient and effective knowledge transfer between different teams. Theoretical optimality bounds are derived and an algorithm is proposed for zero-shot coordination with an ad hoc team. We empirically demonstrate that our method successfully transfers to new teams in a collaborative object-collecting game environment.},
  langid = {english},
  file = {/Users/httran/Zotero/storage/YAWKA3ET/Nigam et al. - Coordination in Ad Hoc Teams with Generalized Policy Improvement.pdf}
}

@inproceedings{nigam2025,
  title = {A {{Survey}} of {{Current Applications}} of {{Inverse Reinforcement Learning}} in {{Aviation}} and {{Future Outlooks}}},
  booktitle = {{{AIAA SCITECH}} 2025 {{Forum}}},
  author = {Nigam, Rupal and Choi, Jimin and Parikh, Niket and Li, Max Z and Tran, Huy T},
  year = {2025},
  address = {Orlando, FL},
  doi = {10.2514/6.2025-1540},
  langid = {english},
  file = {/Users/httran/Zotero/storage/M4BU3BBC/Nigam et al. - A Survey of Current Applications of Inverse Reinforcement Learning in Aviation and Future Outlooks.pdf}
}

@inproceedings{parikh2025,
  title = {Inefficiency of {{Self-Interested Behaviour}} in {{Markov Games}}: {{State-Dependent Price}} of {{Anarchy}}},
  booktitle = {{{AIAA SCITECH}} 2025 {{Forum}}},
  author = {Parikh, Niket and Nigam, Rupal and Li, Max Z and Tran, Huy T},
  year = {2025},
  address = {Orlando, FL},
  doi = {10.2514/6.2025-1929},
  langid = {english},
  file = {/Users/httran/Zotero/storage/AZHDGWC8/Parikh et al. - Inefficiency of Self-Interested Behaviour in Markov Games State-Dependent Price of Anarchy.pdf}
}

@inproceedings{stralen2020,
  title = {Evaluating {{Adaptation Performance}} of {{Hierarchical Deep Reinforcement Learning}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Stralen, Neale Van and Kim, Seung Hyun and Tran, Huy and Chowdhary, Girish},
  year = {2020},
  address = {Paris, France},
  doi = {10.1109/ICRA40945.2020.9197052},
  file = {/Users/httran/Zotero/storage/GYWBCC68/Stralen et al. - 2020 - Evaluating Adaptation Performance of Hierarchical Deep Reinforcement Learning(2).pdf}
}

@inproceedings{stralen2022,
  title = {Feature {{Specialization}} and {{Clustering Improves Hierarchical Sub-task Learning}}},
  booktitle = {Proc. of the {{Adaptive}} and {{Learning Agents Workshop}} ({{ALA}} 2022)},
  author = {Stralen, Neale Van and Kim, Seung and Tran, Huy T and Chowdhary, Girish},
  year = {2022},
  url = {https://ala2022.github.io/papers/ALA2022\_paper\_41.pdf},
  file = {/Users/httran/Zotero/storage/C94VB765/Stralen et al. - 2022 - Feature Specialization and Clustering Improves Hie.pdf}
}

@inproceedings{thompson2018,
  title = {Application of a {{Defender-Attacker-Defender Model}} to the {{U}}.{{S}}. {{Air Transportation Network}}},
  booktitle = {2018 {{IEEE International Symposium}} on {{Technologies}} for {{Homeland Security}} ({{HST}})},
  author = {Thompson, Karl H and Tran, Huy T},
  year = {2018},
  pages = {1--5},
  address = {Woburn, MA},
  doi = {10.1109/THS.2018.8574199},
  file = {/Users/httran/Zotero/storage/QIKD363D/Thompson, Tran - 2018 - Application of a Defender-Attacker-Defender Model to the U.S. Air Transportation Network.pdf}
}

@article{thompson2020,
  title = {Operational {{Perspectives}} into the {{Resilience}} of the {{US Air Transportation Network Against Intelligent Attacks}}},
  author = {Thompson, Karl H and Tran, Huy T},
  year = {2020},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {21},
  number = {4},
  doi = {10.1109/TITS.2019.2909177},
  file = {/Users/httran/Zotero/storage/YRLFBCJ5/Thompson, Tran - 2020 - Operational Perspectives into the Resilience of the US Air Transportation Network Against Intelligent Attacks(2).pdf}
}

@inproceedings{tran2014,
  title = {Trade-Offs {{Between Command}} and {{Control Architectures}} and {{Force Capabilities Using Battlespace Awareness}}},
  booktitle = {19th {{International Command}} and {{Control Research}} and {{Technology Symposium}}},
  author = {Tran, Huy T and Domercant, Jean Charles and Mavris, Dimitri},
  year = {2014},
  address = {Alexandria, VA},
  file = {/Users/httran/Zotero/storage/CITSVHFJ/2014-Trade-offs_Between_Command_and_Control_Architectures_and_Force_Capabilities_Using_Battlespace_Awareness.pdf}
}

@inproceedings{tran2015a,
  title = {A {{System-of-Systems Approach}} for {{Assessing}} the {{Resilience}} of {{Reconfigurable Command}} and {{Control Networks}}},
  booktitle = {{{AIAA Infotech}} @ {{Aerospace}}},
  author = {Tran, Huy T and Domercant, Jean Charles and Mavris, Dimitri N},
  year = {2015},
  address = {Kissimmee, FL},
  doi = {10.2514/6.2015-0640},
  file = {/Users/httran/Zotero/storage/J5B7EUDU/2015-A_System-of-Systems_Approach_for_Assessing_the_Resilience_of_Reconfigurable_Command_and_Control_Networks.pdf}
}

@article{tran2015c,
  title = {Evaluating the Agility of Adaptive Command and Control Networks from a Cyber Complex Adaptive Systems Perspective},
  author = {Tran, H. T. and Domercant, J. C. and Mavris, D. N.},
  year = {2015},
  journal = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
  volume = {12},
  number = {4},
  pages = {405--422},
  issn = {1548-5129},
  doi = {10.1177/1548512915592517},
  isbn = {1548512915},
  keywords = {agent-based modeling,agility,c2,c4isr,command and control,complex networks,cyber complex adaptive systems},
  file = {/Users/httran/Zotero/storage/4YAXBKYY/Tran, Domercant, Mavris - 2015 - Evaluating the agility of adaptive command and control networks from a cyber complex adaptive systems p.pdf}
}

@inproceedings{tran2016,
  title = {A {{Network-based Cost Comparison}} of {{Resilient}} and {{Robust System-of-Systems}}},
  booktitle = {Procedia {{Computer Science}}},
  author = {Tran, Huy T. and Domer{\c c}ant, Jean Charles and Mavris, Dimitri N.},
  year = {2016},
  volume = {95},
  pages = {126--133},
  publisher = {Elsevier Masson SAS},
  issn = {18770509},
  doi = {10.1016/j.procs.2016.09.302},
  isbn = {1-4048-9465-9},
  file = {/Users/httran/Zotero/storage/Q4WVAGKK/2016-A_Network-based_Cost_Comparison_of_Resilient_and_Robust_System-of-Systems.pdf}
}

@inproceedings{tran2017,
  title = {Designing {{Resilient System-of-Systems Networks}}},
  booktitle = {2017 11th {{Annual IEEE International Systems Conference}} ({{SysCon}})},
  author = {Tran, Huy T and Domercant, Jean Charles and Mavris, Dimitri N},
  year = {2017},
  pages = {1--6},
  address = {Montreal, Quebec},
  doi = {10.1109/SYSCON.2017.7934813},
  file = {/Users/httran/Zotero/storage/FT97KYBB/Tran, Domercant, Mavris - 2017 - Designing Resilient System-of-Systems Networks.pdf}
}

@article{tran2017a,
  title = {A Framework for the Quantitative Assessment of Performance-Based System Resilience},
  author = {Tran, Huy T and Balchanos, Michael and Domercant, Jean Charles and Mavris, Dimitri N},
  year = {2017},
  journal = {Reliability Engineering and System Safety},
  volume = {158},
  pages = {73--84},
  doi = {10.1016/j.ress.2016.10.014},
  file = {/Users/httran/Zotero/storage/7PGSHF8J/2017-A_framework_for_the_quantitative_assessment_of_performance-based_system_resilience.pdf}
}

@article{tran2019,
  title = {Parametric {{Design}} of {{Resilient Complex Networked Systems}}},
  author = {Tran, Huy T and Domerc, Jean Charles and Mavris, Dimitri N},
  year = {2019},
  journal = {IEEE Systems Journal},
  volume = {13},
  number = {2},
  pages = {1496--1504},
  doi = {10.1109/JSYST.2018.2825248},
  file = {/Users/httran/Zotero/storage/6QEFRN2B/Tran, Domerc, Mavris - 2019 - Parametric Design of Resilient Complex Networked Systems.pdf}
}

@article{wong2020,
  title = {Data-Driven {{Analysis}} of {{Resilience}} in {{Airline Networks}}},
  author = {Wong, Allen and Tan, Sijian and Chandramouleeswaran, Keshav Ram and Tran, Huy T},
  year = {2020},
  journal = {Transportation Research Part E: Logistics and Transportation Review},
  volume = {143},
  doi = {10.1016/j.tre.2020.102068},
  keywords = {air transportation,anomaly detection,data analytics,network theory,resilience},
  file = {/Users/httran/Zotero/storage/DLC89E2I/Wong et al. - 2020 - Data-driven Analysis of Resilience in Airline Networks(2).pdf}
}

@article{yuasa2024,
  title = {On {{Generating Explanations}} for {{Reinforcement Learning Policies}}: {{An Empirical Study}}},
  shorttitle = {On {{Generating Explanations}} for {{Reinforcement Learning Policies}}},
  author = {Yuasa, Mikihisa and Tran, Huy T. and Sreenivas, Ramavarapu S.},
  year = {2024},
  journal = {IEEE Control Syst. Lett.},
  volume = {8},
  pages = {3027--3032},
  issn = {2475-1456},
  doi = {10.1109/LCSYS.2024.3519301},
  url = {https://ieeexplore.ieee.org/document/10804622/},
  urldate = {2025-01-06},
  abstract = {Explaining reinforcement learning policies is important for deploying them in real-world scenarios. We introduce a set of linear temporal logic formulae designed to provide such explanations, and an algorithm for searching through those formulae for the one that best explains a given policy. Our key idea is to compare action distributions from the target policy with those from policies optimized for candidate explanations. This comparison provides more insight into the target policy than existing methods and avoids inference of ``catch-all'' explanations. We demonstrate our method in a simulated game of capture-the-flag, a car-parking environment, and a robot navigation task.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/httran/Zotero/storage/2AC2RTWV/Yuasa et al. - 2024 - On Generating Explanations for Reinforcement Learning Policies An Empirical Study.pdf}
}
